{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.MNIST_using_PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ0cak3i9Uv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing libraries\n",
        "import torch\n",
        "#library for neural network\n",
        "from torch import nn\n",
        "#For weight optimisation\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "#For datasets and transformation of dataset\n",
        "from torchvision import datasets,transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OAFkIO0Ywxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For visualising the result\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUhaDoxN-FIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading the data\n",
        "\n",
        "#Transforming the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "#Reading the dataset to tensor\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
        "#loading in batch of 64\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_rKANDP_XUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the model\n",
        "model = nn.Sequential(nn.Linear(784,128), nn.ReLU(),nn.Linear(128,64),nn.ReLU(),nn.Linear(64,10),nn.LogSoftmax(dim=1))\n",
        "#Cretaing the Negative Log Loss\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(),lr =0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_szQ6ANA96h",
        "colab_type": "code",
        "outputId": "46891674-c7ec-438e-8364-f49177f8d950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Running the model for 5 epochs\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images,labels in trainloader:\n",
        "    #Reshaping the images\n",
        "    images = images.view(images.shape[0],-1)\n",
        "    #Setting the gradients to zero else they add up\n",
        "    optimizer.zero_grad() \n",
        "    #Forward Propogation\n",
        "    output = model.forward(images)\n",
        "    #Calculate the loss\n",
        "    loss = criterion(output,labels)\n",
        "    #Backward propogate\n",
        "    loss.backward()\n",
        "    #Update the weights\n",
        "    optimizer.step()\n",
        "    #Calculate total loss\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(\"Training Loss:\",(running_loss/len(trainloader)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss: 1.9385727271596507\n",
            "Training Loss: 0.8988254869670502\n",
            "Training Loss: 0.5442559086183495\n",
            "Training Loss: 0.4416542255134979\n",
            "Training Loss: 0.3932131126459473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6anXfomrDnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Vlpx4SWF2i",
        "colab_type": "code",
        "outputId": "0dcee156-973b-4f75-d2dc-df6ae7e9f52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "#Checking for the probablities\n",
        "img = images[2].view(1,784)\n",
        "#Setting gradients to no for faster calculation\n",
        "with torch.no_grad():\n",
        "  logits=model.forward(img)\n",
        "#calculating the probabilities with softmax as the outputs are logits\n",
        "ps = F.softmax(logits,dim=1)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T8zMCZS/gN3tAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}